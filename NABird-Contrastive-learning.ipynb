{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import albumentations as A\n",
    "from torchvision import transforms, datasets\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [01:01<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "path_to_image = {}\n",
    "for i in tqdm(range(0, 23)):\n",
    "    path = '/scratch/sm9669/nabird pickle/nabird/train_'+str(i*1000)+'.pkl'\n",
    "    file = open(path,'rb')\n",
    "    sub_data = pickle.load(file)\n",
    "    path_to_image.update(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5071, 0.4867, 0.4408)\n",
    "std = (0.2675, 0.2565, 0.2761)\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=299, scale=(0.2, 1.)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    image= path_to_image[path]\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    im_pil = Image.fromarray(img)\n",
    "#     return Image.open(path).convert('RGB')\n",
    "    return im_pil\n",
    "\n",
    "class NABirds(data.Dataset):\n",
    "    def __init__(self, root, meta_data, split_name, im_size_resize, im_size_crop, is_train=True, meta_type='ebird_meta', transforms=None):\n",
    "\n",
    "        # load annotations\n",
    "        print('Loading annotations from: ' + os.path.basename(meta_data))\n",
    "        with open(meta_data) as fp:\n",
    "            da = json.load(fp)\n",
    "\n",
    "        # only choose images that are available - ie some missing from download\n",
    "        # also select the split of interest\n",
    "        da = [dd for dd in da[split_name] if dd['valid_image']]\n",
    "\n",
    "        # set up the filenames and annotations\n",
    "        self.imgs = [dd['im_path'] for dd in da]\n",
    "        self.classes = [dd['class_id'] for dd in da]\n",
    "        self.users = [dd[meta_type]['user_id'] for dd in da]\n",
    "        self.dates = [dd[meta_type]['date'] for dd in da]\n",
    "        self.lon = [dd[meta_type]['lon'] for dd in da]\n",
    "        self.lat = [dd[meta_type]['lat'] for dd in da]\n",
    "\n",
    "        # print out some stats\n",
    "#         print split_name\n",
    "#         print '\\t' + str(len(self.imgs)) + ' images'\n",
    "#         print '\\t' + str(len(set(self.classes))) + ' classes'\n",
    "\n",
    "        self.root = root\n",
    "        self.is_train = is_train\n",
    "        self.loader = default_loader\n",
    "        self.im_size_resize = im_size_resize\n",
    "        self.im_size_crop = im_size_crop\n",
    "        self.transforms = transforms # added to this \n",
    "\n",
    "        # augmentation params\n",
    "        self.mu_data = [0.485, 0.456, 0.406]\n",
    "        self.std_data = [0.229, 0.224, 0.225]\n",
    "        self.brightness = 0.4\n",
    "        self.contrast = 0.4\n",
    "        self.saturation = 0.4\n",
    "        self.hue = 0.25\n",
    "\n",
    "        # augmentations\n",
    "#         self.resize = transforms.Resize(self.im_size_resize)\n",
    "#         self.resize_rand = transforms.RandomResizedCrop(self.im_size_crop)\n",
    "#         self.center_crop = transforms.CenterCrop(self.im_size_crop)\n",
    "#         self.flip_aug = transforms.RandomHorizontalFlip()\n",
    "#         self.color_aug = transforms.ColorJitter(self.brightness, self.contrast, self.saturation, self.hue)\n",
    "#         self.tensor_aug = transforms.ToTensor()\n",
    "#         self.norm_aug = transforms.Normalize(mean=self.mu_data, std=self.std_data)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.imgs[index]\n",
    "        im_id = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        class_id = self.classes[index]\n",
    "\n",
    "        if self.is_train:\n",
    "            #img = self.resize_rand(img)\n",
    "            #img = self.flip_aug(img)\n",
    "            #img = self.color_aug(img)\n",
    "            #print(\"su\")\n",
    "            z = \"sumit\"\n",
    "        else:\n",
    "            img = self.resize(img)\n",
    "            img = self.center_crop(img)\n",
    "\n",
    "#         img = self.tensor_aug(img)\n",
    "#         img = self.norm_aug(img)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = [self.transforms(img), self.transforms(img)]\n",
    "        \n",
    "        return img, class_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = '/scratch/sm9669/nabirds_with_loc_2019.json'\n",
    "data_root = '/nabirds/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations from: nabirds_with_loc_2019.json\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NABirds(data_root, meta_data,\n",
    "                     split_name='train', im_size_crop=299,\n",
    "                     im_size_resize=342, is_train=True,transforms = train_transform)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128,\n",
    "               shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_loader)\n",
    "first = next(it)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "    \n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "class Linear_layer(nn.Module):\n",
    "    def __init__(self, input_dim,output_dim,feat_dim, head='mlp'):\n",
    "        super(Linear_layer, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        if head == 'linear':\n",
    "            self.head = nn.Linear(dim_in, feat_dim)\n",
    "        elif head == 'mlp':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(2048, feat_dim)\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                'head not supported: {}'.format(head))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat = self.fc(x)\n",
    "        feat = F.normalize(self.head(feat), dim=1)\n",
    "        return feat\n",
    "\n",
    "\n",
    "class SupConResNet(nn.Module):\n",
    "    def __init__(self, name='resnet50', head='mlp', feat_dim=1024):\n",
    "        super(SupConResNet, self).__init__()\n",
    "        self.encoder = models.inception_v3(pretrained=True,aux_logits =False)\n",
    "        self.encoder.fc = Linear_layer(2048, 2048,feat_dim, head)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        return feat\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SupConResNet()\n",
    "criterion = SupConLoss(temperature=0.1)\n",
    "model = model.cuda()\n",
    "criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =  0.5\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                          lr=lr,\n",
    "                          momentum=0.9,\n",
    "                          weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    epoch_loss=0\n",
    "    \n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        #print(type(images[0]))\n",
    "        images = torch.cat([images[0], images[1]], dim=0)\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # warm-up learning rate\n",
    "        #warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "\n",
    "        # compute loss\n",
    "        features = model(images)\n",
    "        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "        #print(features.shape)\n",
    "        loss = criterion(features, labels)\n",
    "        epoch_loss+=loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch {} - Train Loss {:.2f}'.format(epoch + 1, epoch_loss ))\n",
    "    PATH = '/scratch/sm9669/nabird pickle/model_'+str(epoch+1)+'_'+str(epoch_loss)+'_inceptionV3.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    #print('Training Accuracy {:.4f}'.format(train_correct_total * 100 / count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss 1256.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [27:21<10:56:47, 820.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss 1033.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [41:02<10:43:05, 820.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss 938.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [54:42<10:28:58, 820.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss 888.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [1:08:23<10:15:36, 820.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss 843.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [1:22:03<10:01:44, 820.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss 815.12\n",
      "Epoch 7 - Train Loss 791.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [1:37:03<10:06:29, 846.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss 746.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [2:07:16<9:59:56, 877.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss 714.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [2:22:05<9:47:44, 881.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss 680.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [2:36:16<9:26:58, 872.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train Loss 669.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [2:49:58<9:02:43, 856.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Train Loss 658.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [3:03:40<8:41:51, 846.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Train Loss 637.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [3:17:23<8:23:35, 839.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train Loss 621.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [3:31:05<8:06:32, 834.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train Loss 607.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [3:44:46<7:50:21, 830.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Train Loss 595.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [3:58:28<7:35:11, 827.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Train Loss 582.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [4:12:11<7:20:44, 826.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Train Loss 566.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [4:25:54<7:06:20, 825.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Train Loss 561.95\n",
      "Epoch 20 - Train Loss 553.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [4:39:54<6:54:49, 829.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Train Loss 560.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [5:10:31<6:48:11, 874.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Train Loss 547.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [5:25:02<6:33:07, 873.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Train Loss 540.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [5:38:45<6:12:02, 858.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Train Loss 543.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [5:52:28<5:53:17, 847.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Train Loss 541.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [6:06:11<5:36:04, 840.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Train Loss 530.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [6:19:54<5:20:05, 835.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Train Loss 523.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [6:33:36<5:04:45, 831.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Train Loss 518.41\n",
      "Epoch 29 - Train Loss 511.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [7:01:02<4:35:38, 826.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Train Loss 514.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [7:14:44<4:21:27, 825.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Train Loss 515.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [7:28:28<4:07:33, 825.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Train Loss 504.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [7:42:12<3:53:39, 824.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Train Loss 507.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [7:55:53<3:39:40, 823.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 - Train Loss 499.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [8:09:35<3:25:46, 823.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 - Train Loss 494.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [8:23:17<3:11:58, 822.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 - Train Loss 490.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [8:37:00<2:58:16, 822.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 - Train Loss 496.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [8:50:43<2:44:34, 822.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 - Train Loss 490.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [9:04:26<2:30:52, 822.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 - Train Loss 499.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [9:18:09<2:17:10, 823.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 - Train Loss 492.65\n",
      "Epoch 41 - Train Loss 482.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [9:55:05<2:10:57, 982.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 - Train Loss 479.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [10:08:48<1:49:01, 934.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 - Train Loss 481.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [10:22:30<1:30:05, 900.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 - Train Loss 476.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [10:36:13<1:13:06, 877.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 - Train Loss 476.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [10:49:55<57:23, 860.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 - Train Loss 467.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [11:03:36<42:26, 848.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 - Train Loss 473.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [11:17:18<28:01, 840.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 - Train Loss 474.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [11:30:59<13:55, 835.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 - Train Loss 464.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [11:44:42<00:00, 845.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - Train Loss 465.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(0, 50)):\n",
    "    #lr = lr * (0.1 ** (epoch // 50))\n",
    "    #adjust_learning_rate(epoch)\n",
    "    eta_min = lr * (0.1 ** 3)\n",
    "    lr = eta_min + (lr - eta_min) * (\n",
    "            1 + math.cos(math.pi * epoch / 50)) / 2\n",
    "\n",
    "    train(train_loader, model, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/scratch/sm9669/nabird pickle/model_4_inceptionV3.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 27 03:13:58 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro RTX 8000     On   | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   38C    P0    53W / 250W |      0MiB / 45556MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
